{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('')  # Update the path\n",
        "\n",
        "# Data exploration and visualization\n",
        "numerical_columns = df.iloc[:, 1:].select_dtypes(include=[np.number]).columns\n",
        "\n",
        "\n",
        "# Data preprocessing\n",
        "features = df.drop(['PF_NO', 'Diagnosis'], axis=1)  # Remove 'PF_NO' and 'Diagnosis'\n",
        "target = df['Diagnosis']\n",
        "\n",
        "# Converting categorical variables to numerical using one-hot encoding\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "rfc_accuracy = accuracy_score(y_test, y_pred)\n",
        "rfc_sensitivity = recall_score(y_test, y_pred)\n",
        "rfc_specificity = recall_score(y_test, y_pred, pos_label=0)\n",
        "rfc_precision = precision_score(y_test, y_pred)\n",
        "rfc_f1_score = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Random Forest Evaluation:\")\n",
        "print(\"Accuracy:\", rfc_accuracy)\n",
        "print(\"Sensitivity (Recall):\", rfc_sensitivity)\n",
        "print(\"Specificity:\", rfc_specificity)\n",
        "print(\"Precision:\", rfc_precision)\n",
        "print(\"F1 Score:\", rfc_f1_score)\n",
        "\n",
        "# Display feature importances\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "feature_importance_pairs = sorted(zip(X_train.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in feature_importance_pairs:\n",
        "    print(f\"{feature}: {importance}\")\n",
        "\n",
        "\n",
        "\n",
        "# Radar Chart for Feature Importances\n",
        "plt.figure(figsize=(8, 6))\n",
        "features = X_train.columns.tolist()\n",
        "angles = np.linspace(0, 2 * np.pi, len(features), endpoint=False)\n",
        "feature_importances = np.concatenate((feature_importances, [feature_importances[0]]))  # Closing the loop\n",
        "angles = np.concatenate((angles, [angles[0]]))  # Closing the loop\n",
        "ax = plt.subplot(1, 1, 1, polar=True)\n",
        "ax.plot(angles, feature_importances, 'o-', linewidth=2)\n",
        "ax.fill(angles, feature_importances, alpha=0.25)\n",
        "plt.xticks(angles[:-1], features)\n",
        "plt.title('Radar Chart of Feature Importances')\n",
        "plt.yticks([])  # Hide radial ticks\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EPIjiVC1NPpR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}